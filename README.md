9:54 pm and my mother wants me to scrape some good old information about the payment world, what the hell, I've nothing else to do and I'm bored..., challenge accepted. 

Having a look at the popular websites that people manage to get their payment info buzz from, and it seems the popular sites are Payments Dive, The Paypers, and paymentsJournal, going to be a tough decision to see who gets chosen, not.. It's PaymentsDive, I like their name.

10:00 pm, I've come to the realisation that the pizza I put on has started to set off smoke alarms, I'll have to come back to this...

It's the next day, and the house is still intact. I may or may not have gotten slightly distracted, but nonetheless, I'm back.

I have scraped the information needed, such as news title and description, using soup.select_one() and the specific selector needed from Chrome Dev Tools. Now I need to figure out how to get only the h3 and p to display and not the unnecessary data.

5:57 pm, I have gotten the scraper to list the titles of the news that's listed, bar the first one, so I think I'll have to fix the for loop I've added, as that might be the problem.

6.29 pm, I have successfully listed both headings and paragraphs of the latest on payment news, albeit I have discovered an issue, some news that's listed as a trendline within the selector I have called aren't displayed, so I'll have to figure this out, but other than that, it works!

Turns out I don't need those trendlines; I was tripping.

7:39 pm, I think I have completed this; it's very simple and there is definitely room for improvement, but it's done and I like it.